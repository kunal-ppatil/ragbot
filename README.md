# ragbot
AI-Powered RAG Chatbot using LangChain, FAISS &amp; Streamlit | Smart Q&amp;A from CSV
 SDG Insight Chatbot (RAG-powered)
A Retrieval-Augmented Generation (RAG) chatbot that provides intelligent answers based on Sustainable Development Goals (SDG) indicators. Built with LangChain, FAISS, Streamlit, and HuggingFace models.

ğŸ“š Project Overview
This chatbot helps users explore SDG data by answering natural language questions.
It uses:

Document loading: CSV data â†’ cleaned & chunked
Embedding: sentence-transformers/all-MiniLM-L6-v2
Vector store: FAISS for fast semantic retrieval
LLM: google/flan-t5-base via HuggingFaceHub
Frontend: Streamlit-based chatbot UI
ğŸ“ Project Structure
rag-chatbot/
â”‚
â”œâ”€â”€ data/                       # SDG dataset (CSV)
â”‚   â””â”€â”€ sdg.csv
â”‚
â”œâ”€â”€ vectorstore/               # FAISS index
â”‚   â””â”€â”€ faiss_index/
â”‚
â”œâ”€â”€ chatbot/                   # Core modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py         # CSV to documents
â”‚   â”œâ”€â”€ rag_pipeline.py        # Vector store builder
â”‚   â”œâ”€â”€ generate_sample_qa.py  # Script to export sample Q&A
â”‚   â””â”€â”€ app.py                 # Streamlit chatbot UI
â”‚
â”œâ”€â”€ app/                       # Streamlit
â”‚   â””â”€â”€ app.py                 # Streamlit chatbot UI
â”‚
â”œâ”€â”€ sample_outputs/            # Sample generated Q&A
â”‚   â””â”€â”€ sample_qa.csv
â”‚
â”œâ”€â”€ .env                       # API keys
â”œâ”€â”€ requirements.txt           # Libraries
â””â”€â”€ README.md                  # Project overview
ğŸ› ï¸ Tech Stack
Component	Technology
LLM	google/flan-t5-base via HuggingFaceHub
Embeddings	sentence-transformers/all-MiniLM-L6-v2
Vector Store	FAISS
Frameworks	LangChain
Dataset Source	World Bank SDG Indicators
Dashboard	Streamlit
ğŸ“¦ Installation
1. Clone the Repository
git clone https://github.com:yashdew3/ragbot.git
cd rag-chatbot
2. Create Virtual Environment
python -m venv venv
source venv/bin/activate     # on Windows: venv\Scripts\activate
3. Install Dependencies
pip install -r requirements.txt
4. Set Environment Variables
Create a .env file in the root:

HUGGINGFACEHUB_API_TOKEN=your_huggingface_api_key
ğŸ”‘ Get a free API key from https://huggingface.co/settings/tokens

ğŸ§ª Sample Q&A Export (Optional)
If you want to generate sample questions/answers:

# Use generate_sample_qa.py (optional)
python chatbot/generate_sample_qa.py
ğŸ§  How It Works
Data Loading â€“ Loads & previews sdg.csv

Document Conversion â€“ Chunks data into LangChain-compatible documents

Embedding + FAISS â€“ Converts docs into embeddings, stores in FAISS

QA Chain â€“ Uses flan-t5-base + retrieved chunks to generate answers

Chat UI â€“ Streamlit frontend for question answering

ğŸ’¬ Sample Questions
Question	Answer
What is the access to electricity in rural areas in Africa?	68.98945175
How has access to clean fuels changed since 2000?	East Asia & Pacific (excluding low income)
Which countries lead in renewable energy use?	East Asia & Pacific
ğŸ“‚ View full list in: sample_outputs/sample_qa.csv
âœ… Run the Chatbot
streamlit run chatbot/app.py
ğŸ“© Requirements
Python 3.8+
Libraries listed in requirements.txt
ğŸ’¡ Use Cases
Data analytics dashboards

Automated report Q&A bots

Domain-specific chat assistants (healthcare, finance, education)

Research exploration tools

Internal tools for enterprise CSV datasets

ğŸ” Privacy & Offline Use
This chatbot supports offline embeddings using Hugging Face or Llama models. You are free from vendor lock-in and API rate limits.

